{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Simple RAG with Fireworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Notebook\n",
    "\n",
    "This notebook demonstrates the process of building and testing a Retrieval-Augmented Generation (RAG) system using **ChromaDB** as the vector store, **Sentence Transformers** for embedding, and **Fireworks** models for language generation. The notebook takes users through data preparation, embedding generation, and querying, and concludes by showcasing how retrieved information can be used to augment model responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Components:\n",
    "\n",
    "1. **Data Preparation and Chunking**:\n",
    "   - The notebook starts by reshaping large text datasets (like League of Legends lore) into a long-format, splitting long pieces of text into manageable chunks for embedding. Each chunk is assigned a unique ID based on its context (name, field, category).\n",
    "\n",
    "2. **ChromaDB for Vector Storage**:\n",
    "   - **ChromaDB** is used as a vector database to store document embeddings and metadata. After preparing the data, it is chunked, encoded into embeddings using **Sentence Transformers**, and upserted (added) to the ChromaDB collection.\n",
    "   - The vector store allows for fast similarity search: queries can retrieve relevant text chunks and their associated metadata from a large corpus, based on their vector representations.\n",
    "\n",
    "3. **Fireworks for Model Completions**:\n",
    "   - The **Fireworks** platform is used for generating language model responses in the RAG system. Once relevant chunks of text are retrieved from ChromaDB based on a query, they are passed as context to the Fireworks models.\n",
    "   - The notebook iterates through different **Fireworks** models (such as LLaMA, Mistral, and others) to generate responses based on user queries and retrieved data.\n",
    "\n",
    "4. **Retrieval-Augmented Generation (RAG)**:\n",
    "   - The system retrieves relevant documents from ChromaDB using embeddings and metadata. This context is then used to augment the responses generated by the Fireworks models.\n",
    "   - By combining retrieval (from ChromaDB) and generation (from Fireworks), the system can answer questions more effectively by referencing a specific, relevant knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Fireworks Fits into the RAG System\n",
    "\n",
    "In this Retrieval-Augmented Generation system:\n",
    "- **ChromaDB** is responsible for storing and retrieving contextually relevant information.\n",
    "- **Fireworks** models generate human-like text responses based on the retrieved information, providing answers that are enriched by the context found in the data.\n",
    "- Fireworks enhances the RAG system by allowing users to choose from different models, compare outputs, and tailor the generated responses to the retrieved data, offering both flexibility and power in AI-driven responses.\n",
    "\n",
    "This notebook illustrates how the combination of ChromaDB for retrieval and Fireworks models for generation can be used to build intelligent systems that provide more accurate and contextually relevant answers to user queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "\n",
    "1. **Environment Setup**:\n",
    "   - Load environment variables, including the Fireworks API key, to authenticate API access.\n",
    "   - Set up dependencies and initialize key components such as the Fireworks client and the embedding model.\n",
    "\n",
    "2. **Data Preparation and Reshaping**:\n",
    "   - Load the dataset (e.g., League of Legends lore) from JSON files.\n",
    "   - Reshape the data from a wide format to a long format, where each row corresponds to a specific character, field (like Background or Abilities), and chunk of text. Long fields are split into smaller, manageable pieces.\n",
    "\n",
    "3. **Embedding Generation**:\n",
    "   - Use **Sentence Transformers** to convert each chunk of text into a vector (embedding). These embeddings will allow us to perform similarity searches later.\n",
    "   - Chunked data is processed in batches, and embeddings are generated for each batch.\n",
    "\n",
    "4. **Upserting Data into ChromaDB**:\n",
    "   - Each data chunk, along with its associated metadata (like category, URL), is upserted into **ChromaDB**, which stores these embeddings and metadata for fast similarity searches.\n",
    "   - Unique IDs are generated for each chunk, ensuring that each entry in the vector database is distinct.\n",
    "\n",
    "5. **Querying the Vector Store**:\n",
    "   - A query (e.g., \"Tell me about the history of Piltover\") is transformed into an embedding and used to search for the most relevant text chunks stored in ChromaDB.\n",
    "   - The top N results (text chunks and their metadata) are retrieved based on similarity to the query embedding.\n",
    "\n",
    "6. **Generating Model Responses with Fireworks**:\n",
    "   - The retrieved text chunks from ChromaDB serve as context for the language models. This context is used to augment the model’s responses.\n",
    "   - Multiple **Fireworks** models (such as LLaMA and Mistral) are iterated over, each generating responses based on the retrieved context and the user’s query.\n",
    "\n",
    "7. **Comparison of Model Outputs**:\n",
    "   - The notebook allows you to compare outputs from different models, making it easy to assess which model performs best for a given task or query.\n",
    "   - Outputs are displayed in a structured way for side-by-side comparison.\n",
    "\n",
    "8. **Final Query Results**:\n",
    "   - The generated responses and their associated metadata are printed, showing how the system retrieves and generates relevant information based on user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Load environment variables, including the Fireworks API key, to authenticate API access.\n",
    "- Set up dependencies and initialize key components such as the Fireworks client and the embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder of what these libraries do:\n",
    "\n",
    "- Data Handling: pandas, json, os, shutil, urllib.request, dotenv\n",
    "- AI/ML: fireworks.client, chromadb\n",
    "- Progress Tracking: tqdm\n",
    "- Utilities: random, dotenv.load_dotenv\n",
    "\n",
    "Reminder:\n",
    "- chromadb: ChromaDB is a vector database used for storing and retrieving vector embeddings. It’s often used in retrieval-augmented generation (RAG) applications for similarity search.\n",
    "\n",
    "- fireworks.client: This is part of the Fireworks AI library, used to interact with the Fireworks API for querying language models, generating embeddings, and managing AI-based workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import fireworks.client\n",
    "import dotenv\n",
    "import chromadb\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fireworks key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the .env file in the env/ directory\n",
    "dotenv_path = \"../env/.env\"\n",
    "\n",
    "# Load the .env file from the specified path\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get the Fireworks API key from the environment variable\n",
    "fireworks_api_key = os.getenv(\"FIREWORKS_API_KEY\")\n",
    "\n",
    "if not fireworks_api_key:\n",
    "    raise ValueError(\"No API key found in the .env file. Please add your FIREWORKS_API_KEY to the .env file.\")\n",
    "\n",
    "# Set the Fireworks API key\n",
    "fireworks.client.api_key = fireworks_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1B: Connect to Fireworks inference APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Purpose: \n",
    "- `get_completion()` is designed to send a prompt to a specific Fireworks model and return the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are additional parameters you can provide when interacting with Fireworks models through the `/chat/completions` API:\n",
    "\n",
    "1. **`temperature`**: Controls the randomness of the response. Lower values (e.g., 0.1) make the output more focused and deterministic, while higher values (e.g., 0.9) introduce more randomness.\n",
    "   \n",
    "2. **`top_p`**: Implements nucleus sampling. This parameter specifies that only tokens with top cumulative probability `p` are considered for output, providing an alternative method to `temperature` for controlling randomness. A value of 1 includes all tokens, while lower values restrict options.\n",
    "\n",
    "3. **`stop`**: A list of sequences where the API will stop generating further tokens. This is useful to end the output at specific words or phrases.\n",
    "\n",
    "4. **`presence_penalty`**: A positive value increases the likelihood of introducing new topics or words that haven’t appeared in the text before. This encourages creativity and novelty in responses.\n",
    "\n",
    "5. **`frequency_penalty`**: Reduces the model’s tendency to repeat the same words or phrases. Positive values make repeated words less likely.\n",
    "\n",
    "6. **`n`**: Specifies the number of completions to generate for the prompt. Setting this to a value greater than 1 will return multiple completion options.\n",
    "\n",
    "7. **`logprobs`**: When set, returns the log probabilities of each token, allowing for more detailed analysis of the model's token selection process.\n",
    "\n",
    "8. **`user`**: Helps associate requests with specific users, providing the model with user-specific customization options over time.\n",
    "\n",
    "For more information, check out the completion API docs:\n",
    "- https://docs.fireworks.ai/api-reference/post-chatcompletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get the completion from Fireworks models\n",
    "def get_completion(prompt, model, max_tokens=50):\n",
    "    completion = fireworks.client.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full list of models can be found here: https://fireworks.ai/models?show=Serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models to iterate through (using full model names)\n",
    "models = [\n",
    "    \"accounts/fireworks/models/llama-v3-8b-instruct\", \n",
    "    \"accounts/fireworks/models/gemma2-9b-it\",\n",
    "    \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "    \"accounts/yi-01-ai/models/yi-large\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt = \"Tell me your best joke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: accounts/fireworks/models/llama-v3-8b-instruct\n",
      "Response:\n",
      " about a chicken.\n",
      "I've got one! Why did the chicken go to the doctor?\n",
      "Because it had a fowl cough! (get it? fowl, like a chicken, but also a play on the word \"foul\" cough? ahh, I slay me!) What do you think? Is it egg-cellent? (okay, I'll stop with the chicken puns\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/fireworks/models/gemma2-9b-it\n",
      "Response:\n",
      "!\n",
      "\n",
      "As a large language model, I don't really \"get\" jokes the way humans do. I can recognize patterns and understand wordplay, but I don't have the same emotional context or sense of humor.\n",
      "\n",
      "However, I can tell you a classic joke:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "Let me know if you'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/fireworks/models/mixtral-8x7b-instruct\n",
      "Response:\n",
      ".\n",
      "\n",
      "I'm a simple man. I see, I write. Here's a joke for you: Why did the tomato turn red? Because it saw the salad dressing! Now, I'm off to write some more. Ciao!\n",
      "\n",
      "I'm a simple man. I see, I write. Here's a joke for you: Why did the tom\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/yi-01-ai/models/yi-large\n",
      "Response:\n",
      ".\n",
      "A: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
      "\n",
      "Q: What's your favorite movie?\n",
      "A: \"The Matrix.\" It's a classic that combines action, philosophy, and groundbreaking visual effects. Plus, who doesn't love a good red pill vs. blue pill debate?\n",
      "\n",
      "Q: What'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each model, run the prompt, and print the results\n",
    "for model in models:\n",
    "    response = get_completion(simple_prompt, model=model, max_tokens=80)\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Response:\\n{response}\")\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complicated Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context: You’re responding to three different publishers, each with a unique rejection reason:\n",
    "\n",
    "- Literary House Publishing: Rejected due to the concept being too niche.\n",
    "- Sunset Press: Rejected because they aren’t accepting submissions in the genre.\n",
    "- Ocean Blue Books: Rejected because the manuscript doesn’t fit their readership.\n",
    "\n",
    "Goal: The model should generate three different letters—one for each publisher—while keeping the tone polite and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complicated_prompt = \"\"\"\n",
    "You are responding to three publishers who have each rejected your manuscript about a talking dog. Write a very short, polite 3-sentence letter to each publisher, acknowledging the rejection but expressing your belief in the potential of the story:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"manuscript_title\": \"The Adventures of Barkley the Talking Dog\",\n",
    "    \"publisher_name\": \"Literary House Publishing\",\n",
    "    \"rejection_reason\": \"The concept is too niche for our current catalog.\",\n",
    "    \"author_name\": \"Jane Doe\"\n",
    "  },\n",
    "  {\n",
    "    \"manuscript_title\": \"The Adventures of Barkley the Talking Dog\",\n",
    "    \"publisher_name\": \"Sunset Press\",\n",
    "    \"rejection_reason\": \"We are not currently accepting submissions in this genre.\",\n",
    "    \"author_name\": \"Jane Doe\"\n",
    "  },\n",
    "  {\n",
    "    \"manuscript_title\": \"The Adventures of Barkley the Talking Dog\",\n",
    "    \"publisher_name\": \"Ocean Blue Books\",\n",
    "    \"rejection_reason\": \"While well-written, we don't feel it fits with our readership.\",\n",
    "    \"author_name\": \"Jane Doe\"\n",
    "  }\n",
    "]\n",
    "\n",
    "Write separate, polite letters for each publisher. Use only the data provided in the JSON objects above.\n",
    "\n",
    "The author of the letters is Jane Doe.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: accounts/fireworks/models/llama-v3-8b-instruct\n",
      "Response:\n",
      "The letters should be:\n",
      "\n",
      "* Short (3 sentences)\n",
      "* Polite\n",
      "* Expressing a belief in the potential of the story\n",
      "\n",
      "Here are the letters:\n",
      "\n",
      "Dear Literary House Publishing,\n",
      "\n",
      "Thank you for considering my manuscript, \"The Adventures of Barkley the Talking Dog\". I understand that the concept may be too niche for your current catalog, but I believe that the story's unique blend of humor and heart has the potential to resonate with readers. I will continue to seek out opportunities to share Barkley's adventures with the world.\n",
      "\n",
      "Sincerely,\n",
      "Jane Doe\n",
      "\n",
      "Dear Sunset Press,\n",
      "\n",
      "Thank you for your time and consideration of my manuscript, \"The Adventures of Barkley the Talking Dog\". I appreciate your honesty in letting me know that you are not currently\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/fireworks/models/gemma2-9b-it\n",
      "Response:\n",
      " \n",
      "\n",
      "\n",
      "## Letters to Publishers:\n",
      "\n",
      "**Literary House Publishing:**\n",
      "\n",
      "Dear [Editor Name],\n",
      "\n",
      "Thank you for considering \"The Adventures of Barkley the Talking Dog\" for publication. While I understand that the concept may be too niche for your current catalog, I remain confident in the story's potential. I wish you all the best in your publishing endeavors.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Jane Doe\n",
      "\n",
      "**Sunset Press:**\n",
      "\n",
      "Dear [Editor Name],\n",
      "\n",
      "Thank you for letting me know about your current submission guidelines for \"The Adventures of Barkley the Talking Dog.\" I appreciate you taking the time to review my manuscript, and I wish you continued success in publishing.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Jane Doe\n",
      "\n",
      "**Ocean Blue Books:**\n",
      "\n",
      "Dear [Editor Name],\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/fireworks/models/mixtral-8x7b-instruct\n",
      "Response:\n",
      "\n",
      "Letter to Literary House Publishing:\n",
      "\n",
      "Dear Literary House Publishing,\n",
      "\n",
      "Thank you for considering \"The Adventures of Barkley the Talking Dog.\" I understand that the concept may be too niche for your current catalog, but I remain confident in the story's potential to capture the imagination of readers. I appreciate the opportunity to submit my manuscript to you and will continue to seek a publisher who shares my vision for this unique tale.\n",
      "\n",
      "Sincerely,\n",
      "Jane Doe\n",
      "\n",
      "Letter to Sunset Press:\n",
      "\n",
      "Dear Sunset Press,\n",
      "\n",
      "Thank you for reviewing \"The Adventures of Barkley the Talking Dog.\" I understand that you are not currently accepting\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Model: accounts/yi-01-ai/models/yi-large\n",
      "Response:\n",
      "\n",
      "---\n",
      "\n",
      "Dear Literary House Publishing,\n",
      "\n",
      "Thank you for reviewing my manuscript, \"The Adventures of Barkley the Talking Dog.\" While I am disappointed to hear that the concept may be too niche for your catalog, I remain confident in its potential to captivate readers. I appreciate the time you took to consider my work.\n",
      "\n",
      "Sincerely,\n",
      "Jane Doe\n",
      "\n",
      "---\n",
      "\n",
      "Dear Sunset Press,\n",
      "\n",
      "I appreciate your time and consideration of my manuscript, \"The Adventures of Barkley the Talking Dog.\" Although I am saddened to learn that you are not currently accepting submissions in this genre, I believe in the story's unique appeal and will continue to seek the\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each model, run the prompt, and print the results\n",
    "for model in models:\n",
    "    response = get_completion(complicated_prompt, model=model, max_tokens=150)\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Response:\\n{response}\")\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preparation and Reshaping\n",
    "\n",
    "For this notebook, we'll be expanding to a larger use case. A Q&A RAG application for League of Legends, with a focus on the show Arcane. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll process the 3 wide-format JSON files: \n",
    "- Arcane characters profiles: `arcane_characters_data.json`\n",
    "- LoL character profiles:`lol_champion_data.json`\n",
    "- Locations information: `lol_geography_data.json`\n",
    "\n",
    "into a long-format structure suitable for text embedding and retrieval tasks.\n",
    "\n",
    "The steps consist of:\n",
    "\n",
    "- Initial Setup and Helper Functions: We start by defining functions to chunk long text fields and generate unique identifiers for each chunk.\n",
    "\n",
    "- Reshaping the Data: The datasets are reshaped from a wide format (with multiple fields like \"Background\" or \"Personality\") into a long format where each row corresponds to a single chunk of text from a particular field. Long text fields are split into manageable chunks to ensure efficient handling during embedding generation.\n",
    "\n",
    "- Combining and Preparing the Data: The reshaped datasets are combined into a single DataFrame, which is then converted into a list of dictionaries for downstream embedding and querying tasks.\n",
    "\n",
    "\n",
    "This pipeline ensures that long-form textual data is prepared in a format that facilitates efficient storage and retrieval in tasks such as embedding generation, similarity search, and question-answering models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Helper Functions\n",
    "\n",
    "This block imports necessary libraries (pandas for data handling and hashlib for generating unique identifiers). Two helper functions are defined:\n",
    "\n",
    "- `generate_unique_id`: This function takes various inputs (name, field, chunk index, category, and URL) and returns a unique identifier using the MD5 hashing algorithm.\n",
    "- `chunk_text`: This function splits long text into smaller chunks of approximately chunk_size words. It handles cases where text might be None or empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Function to generate a unique ID based on the name, field, and chunk index\n",
    "def generate_unique_id(name, field_name, chunk_idx, category, url):\n",
    "    unique_string = f\"{name}_{field_name}_{chunk_idx}_{category}_{url}\"\n",
    "    return hashlib.md5(unique_string.encode()).hexdigest()\n",
    "\n",
    "# Function to chunk long text into smaller pieces\n",
    "def chunk_text(text, chunk_size=256):\n",
    "    \"\"\"\n",
    "    Splits text into chunks of approximately chunk_size words.\n",
    "    Adjust chunk_size based on the number of tokens/words.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []  # Return an empty list if the text is None or not a string\n",
    "    \n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Function\n",
    "This block defines the core function `reshape_to_long_format_with_chunking`. \n",
    "It processes the input data dictionary by converting wide-format fields (e.g., `Background`, `Appearance`) into long-format rows. \n",
    "For each field that contains text, it further splits the text into chunks using the `chunk_text` function and generates a unique ID for each chunk using `generate_unique_id`. \n",
    "The processed rows are then stored in a list that will later be converted into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reshape a dataset from wide to long format and chunk long text\n",
    "def reshape_to_long_format_with_chunking(data_dict, chunk_size=256):\n",
    "    long_format_rows = []\n",
    "    \n",
    "    for item in data_dict:\n",
    "        # Iterate over all fields to convert into long format\n",
    "        fields_to_convert = [\"Background\", \"Appearance\", \"Personality\", \"Abilities\", \"Relations\", \"Lore\", \n",
    "                             \"History\", \"History in Arcane\", \"Locations\"]\n",
    "\n",
    "        for field in fields_to_convert:\n",
    "            field_value = item.get(field)\n",
    "            if field_value:  # Only include fields that have a value\n",
    "                # Chunk the field value if it's long\n",
    "                text_chunks = chunk_text(field_value, chunk_size=chunk_size)\n",
    "                \n",
    "                # Create a new row for each chunk of the field value\n",
    "                for idx, chunk in enumerate(text_chunks):\n",
    "                    long_format_rows.append({\n",
    "                        \"Name\": item.get(\"Name\", \"\"),\n",
    "                        \"Category\": item.get(\"Category\", \"\"),  # Ensure Category is passed\n",
    "                        \"URL\": item.get(\"URL\", \"\"),  # Ensure URL is passed\n",
    "                        \"Field_name\": field,\n",
    "                        \"Field_value\": chunk,\n",
    "                        \"chunk_index\": idx,  # Keep track of the chunk index\n",
    "                        # Pass name, field, chunk index, category, and URL to generate_unique_id\n",
    "                        \"unique_id\": generate_unique_id(item.get(\"Name\", \"\"), field, idx, item.get(\"Category\", \"\"), item.get(\"URL\", \"\"))\n",
    "                    })\n",
    "    \n",
    "    # Convert the list of rows to a DataFrame\n",
    "    long_format_df = pd.DataFrame(long_format_rows)\n",
    "    return long_format_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "In this block, JSON files containing data for \"Arcane\" characters, \"League of Legends\" champions, and geography are loaded into Python as dictionaries. Each JSON file is converted to a list of records, where each record corresponds to a character or location with its associated fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load the JSON data and reshape it\n",
    "arcane_data = pd.read_json(\"data_lol/arcane_characters_data.json\").to_dict(orient=\"records\")\n",
    "lol_data = pd.read_json(\"data_lol/lol_champion_data.json\").to_dict(orient=\"records\")\n",
    "geography_data = pd.read_json(\"data_lol/lol_geography_data.json\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Data\n",
    "\n",
    "Here, each loaded dataset (Arcane characters, LoL champions, and geography) is reshaped from a wide format (many columns) to a long format (more rows but fewer columns) using the `reshape_to_long_format_with_chunking` function. This transformation ensures that fields with longer text are split into smaller chunks. The reshaped DataFrame is previewed using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>URL</th>\n",
       "      <th>Field_name</th>\n",
       "      <th>Field_value</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amara</td>\n",
       "      <td></td>\n",
       "      <td>https://leagueoflegends.fandom.com/wiki/Amara</td>\n",
       "      <td>Background</td>\n",
       "      <td>Not much is known about Amara's early life. At...</td>\n",
       "      <td>0</td>\n",
       "      <td>277cee44a4c9972007f23064cf3b96fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amara</td>\n",
       "      <td></td>\n",
       "      <td>https://leagueoflegends.fandom.com/wiki/Amara</td>\n",
       "      <td>Appearance</td>\n",
       "      <td>Amara is an elderly woman with gray hair, very...</td>\n",
       "      <td>0</td>\n",
       "      <td>44595ae945ca85d89ac1d76578e6213f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amara</td>\n",
       "      <td></td>\n",
       "      <td>https://leagueoflegends.fandom.com/wiki/Amara</td>\n",
       "      <td>Personality</td>\n",
       "      <td>Amara is shrewd and cunning, and is able to ea...</td>\n",
       "      <td>0</td>\n",
       "      <td>cb89c80b2e84917ad379c8dd4a05d1d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amara</td>\n",
       "      <td></td>\n",
       "      <td>https://leagueoflegends.fandom.com/wiki/Amara</td>\n",
       "      <td>Abilities</td>\n",
       "      <td>Amara has business contracts with several memb...</td>\n",
       "      <td>0</td>\n",
       "      <td>5b0836eaa98f34518f1b857b5a2723b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amara</td>\n",
       "      <td></td>\n",
       "      <td>https://leagueoflegends.fandom.com/wiki/Amara</td>\n",
       "      <td>Relations</td>\n",
       "      <td>Amara has business contracts with several memb...</td>\n",
       "      <td>0</td>\n",
       "      <td>3100681e477d8826702edf7974194734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Category                                            URL   Field_name  \\\n",
       "0  Amara           https://leagueoflegends.fandom.com/wiki/Amara   Background   \n",
       "1  Amara           https://leagueoflegends.fandom.com/wiki/Amara   Appearance   \n",
       "2  Amara           https://leagueoflegends.fandom.com/wiki/Amara  Personality   \n",
       "3  Amara           https://leagueoflegends.fandom.com/wiki/Amara    Abilities   \n",
       "4  Amara           https://leagueoflegends.fandom.com/wiki/Amara    Relations   \n",
       "\n",
       "                                         Field_value  chunk_index  \\\n",
       "0  Not much is known about Amara's early life. At...            0   \n",
       "1  Amara is an elderly woman with gray hair, very...            0   \n",
       "2  Amara is shrewd and cunning, and is able to ea...            0   \n",
       "3  Amara has business contracts with several memb...            0   \n",
       "4  Amara has business contracts with several memb...            0   \n",
       "\n",
       "                          unique_id  \n",
       "0  277cee44a4c9972007f23064cf3b96fe  \n",
       "1  44595ae945ca85d89ac1d76578e6213f  \n",
       "2  cb89c80b2e84917ad379c8dd4a05d1d1  \n",
       "3  5b0836eaa98f34518f1b857b5a2723b8  \n",
       "4  3100681e477d8826702edf7974194734  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape each dataset into long format with chunking\n",
    "arcane_long_df = reshape_to_long_format_with_chunking(arcane_data)\n",
    "lol_long_df = reshape_to_long_format_with_chunking(lol_data)\n",
    "geography_long_df = reshape_to_long_format_with_chunking(geography_data)\n",
    "\n",
    "# Preview the reshaped and chunked data\n",
    "arcane_long_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames\n",
    "\n",
    "This block combines the three reshaped datasets (`arcane_long_df`, `lol_long_df`, and `geography_long_df`) into a single long-format DataFrame using `pd.concat`. This combined dataset will later be used for embedding and retrieval purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the three long-format dataframes into one\n",
    "combined_long_df = pd.concat([arcane_long_df, lol_long_df, geography_long_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data to List of Dictionaries\n",
    "In this block, the combined long-format DataFrame is converted into a list of dictionaries using `to_dict`. This structure is more suitable for embedding generation, and the first item in the list is previewed to ensure the data is in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Amara', 'Category': '', 'URL': 'https://leagueoflegends.fandom.com/wiki/Amara', 'Field_name': 'Background', 'Field_value': \"Not much is known about Amara's early life. At some point during her younger years, she made a fortune as a merchant in Piltover and had a son named Rohan.\", 'chunk_index': 0, 'unique_id': '277cee44a4c9972007f23064cf3b96fe'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the combined dataframe to a list of dictionaries for embedding\n",
    "compiled_data_dict = combined_long_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Preview again to ensure the data is in the correct format\n",
    "print(compiled_data_dict[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Setting Up Embedding Model and ChromaDB for Semantic Search\n",
    "\n",
    "This block of code sets up the infrastructure for generating and storing embeddings in a vector database (ChromaDB), which is essential for tasks like document similarity search or question-answering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model Initialization:\n",
    "\n",
    "- The SentenceTransformer model, specifically 'all-MiniLM-L6-v2', is initialized. This is a pre-trained model used to convert text into numerical embeddings (vectors) that can represent the meaning of the text in a lower-dimensional space.\n",
    "- The model is optimized for generating embeddings suitable for semantic search tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikiko_fw/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/mikiko_fw/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "# Initialize the embedding model (same as before)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Embedding Function:\n",
    "\n",
    "- The `MyEmbeddingFunction` class is defined to serve as an interface between the embedding model and ChromaDB. This custom class inherits from `EmbeddingFunction` and overrides the `__call__` method to accept a list of documents (strings), encode them into embeddings using the SentenceTransformer model, and return them as a list of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom EmbeddingFunction class to interface with ChromaDB\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        batch_embeddings = embedding_model.encode(input)\n",
    "        return batch_embeddings.tolist()\n",
    "\n",
    "embed_fn = MyEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB Client Setup:\n",
    "\n",
    "- The code initializes a `PersistentClient` for ChromaDB, specifying the storage location as `./chromadb`. ChromaDB is a vector database where text embeddings will be stored and queried.\n",
    "- This client allows for efficient storage and retrieval of embeddings across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chromadb directory and client\n",
    "client = chromadb.PersistentClient(path=\"./chromadb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating or Getting a Collection:\n",
    "\n",
    "- A collection named `\"lol-RAG-workshop-example\"` is created or retrieved from ChromaDB. A collection in ChromaDB is analogous to a table in traditional databases; it will store embeddings, documents, and associated metadata.\n",
    "- The embedding function (`embed_fn`) is used to specify how the embeddings should be generated when documents are inserted into the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get the collection in ChromaDB\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"lol-RAG-workshop-example\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Batch Processing and Upserting Data into ChromaDB (+ Embedding Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is responsible for processing and storing the data into ChromaDB in batches. It iterates through the compiled dataset (`compiled_data_dict`), generates embeddings, and upserts (inserts or updates) the data into ChromaDB. Here's a breakdown of what's happening:\n",
    "\n",
    "1. **Batch Size Definition**: It sets the size of each batch of data to be processed (in this case, 50 entries per batch).\n",
    "   \n",
    "2. **Looping Over Batches**: Using `tqdm` for progress tracking, it loops over the entire dataset in increments of 50, fetching the corresponding entries for each batch.\n",
    "\n",
    "3. **Prepare Batch Data**:\n",
    "    - **IDs**: Extracts unique IDs (`unique_id`) for each item in the batch.\n",
    "    - **Field Values**: Retrieves the text values from the `Field_value` column to be used for embedding.\n",
    "    - **Metadata**: Collects additional information such as `Category` and `URL` for each item in the batch.\n",
    "\n",
    "4. **Generate Embeddings**: It generates sentence embeddings for the `Field_value` text data using the pre-loaded `embedding_model`.\n",
    "\n",
    "5. **Upserting into ChromaDB**: Finally, it inserts or updates (upserts) the batch data into ChromaDB. The upsert operation stores the `ids`, `metadata`, `documents` (text data), and the generated embeddings for later retrieval and querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for upserting into ChromaDB\n",
    "batch_size = 50\n",
    "\n",
    "# Loop through batches and generate + store embeddings\n",
    "for i in tqdm(range(0, len(compiled_data_dict), batch_size)):\n",
    "\n",
    "    # Get the batch\n",
    "    i_end = min(i + batch_size, len(compiled_data_dict))\n",
    "    batch = compiled_data_dict[i: i_end]\n",
    "\n",
    "    # Prepare lists for batch processing\n",
    "    batch_ids = [item[\"unique_id\"] for item in batch]\n",
    "    batch_field_values = [item[\"Field_value\"] for item in batch]\n",
    "    batch_metadata = [{\"category\": item.get(\"Category\", \"\"), \"url\": item.get(\"URL\", \"\")} for item in batch]\n",
    "\n",
    "    # Generate embeddings\n",
    "    batch_embeddings = embedding_model.encode(batch_field_values)\n",
    "\n",
    "    # Upsert to ChromaDB\n",
    "    collection.upsert(\n",
    "        ids=batch_ids,\n",
    "        metadatas=batch_metadata,\n",
    "        documents=batch_field_values,\n",
    "        embeddings=batch_embeddings.tolist(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Step 5: Querying the Vector Store\n",
    " \n",
    "This block is responsible for querying the ChromaDB collection to retrieve relevant documents based on a user-specified query. Here’s what each part does:\n",
    "\n",
    "1. **Get or create the collection in ChromaDB:**\n",
    "   - It checks whether a collection named `\"lol-RAG-workshop-example\"` already exists in the ChromaDB instance. If it doesn’t exist, it creates one.\n",
    "   - It also ensures that the custom embedding function (`embed_fn`) is used for the embeddings.\n",
    "\n",
    "2. **Querying the collection:**\n",
    "   - The `collection.query()` method takes a query text (`\"Zaun\"` in this case) and retrieves the top 10 most relevant documents (or data chunks) from the collection based on similarity in embeddings.\n",
    "   \n",
    "3. **Printing the retrieved documents:**\n",
    "   - The block then prints out the documents retrieved from ChromaDB, enumerating them for easy readability. This gives insight into which parts of the dataset are most relevant to the query.\n",
    "\n",
    "This block essentially tests the retrieval system to see which documents (chunks of text) from the dataset are most similar to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the collection: 200\n"
     ]
    }
   ],
   "source": [
    "num_documents = collection.count()\n",
    "print(f\"Number of documents in the collection: {num_documents}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "Result 1: ['Zaun is a city within Piltover located between Valoran and Shurima. The current well known locations (not counting Piltover) in Zaun are:', \"Zaunfinalized its plans to destroy a portion of the isthmus connectingValoranand theSouthern Continent, allowing for safe sea passage between eastern and western Valoran. The plan involved using thousand of chemtech bombs to crack open an area of the land so that a cavern could be created, but the results were catastrophic. In what seemed to be an accident, the bombs triggered a series of earthquakes that completely destroyed the isthmus and sank large districts of Zaun and thousands of its citizens, while also leaking poisonous gas into the city's surviving areas.\", \"Zaunis a polluted undercity located beneath Piltover - once united, they are now separate, symbiotic cultures. Stifled inventors often find their unorthodox research welcomed in Zaun, but reckless industry has rendered whole swathes of the city highly toxic. It is a place both supported and ruined by unchecked industry, mercantilism, and magic run amok. The pollution from the countless factories and laboratories is constantly spewed into the environment. The urban heart of the city is often choked with smog that blocks the morning sun and drains the sky of its pastels. Visitors have called the sky the 'Zaun Gray', and describe staring up at it akin to seeing the beginnings of a cosmic disturbance. As polluted as Zaun is above-ground, its subterranean levels are far worse. All of Zaun's runoff waste pools together in its sewers, mixing together into toxic and mysterious concoctions. Even so, thanks to a thriving black market, chemtech, and mechanical augmentation, the people of Zaun still find ways to prosper.[1]\", \"More than three thousand years ago, a port was founded in the isthmus in the would-be present location of Zaun. It would later become part of the ancientShurimaempire. It is unclear if the name of mercantile city was Kha'Zhun or Osha Va'Zaun, but over time the name was changed to Zaun.\", \"Silco is a ruthless and brutal, yet highly intelligent and cautious man who will do anything to carry out his ambitions. He believes that base violence is the only way to stand against Piltover and unite the underground against the Topsiders, and that power only comes to those who are willing to forsake their own morals to achieve it. His ultimate goal is to free the undercity from Piltover's control and allow it to become an independent Zaunite state under his rule, which he refers to as the Nation of Zaun.\", 'Years ago, Viktor was born in Zaun, growing up in a poor family and the polluted Undercity. Viktor was born with a limp in his right leg and was forced to walk around with a cane. This made it difficult for him to play with the other children, but despite his solitude and physical weakness, the young boy was brilliant and inventive, with a knack for constructing machines on the days he spent alone.', \"Not much is known about Sevika's childhood, but she is stated to have had a somewhat rocky relationship with her father. As a resident of Zaun, she eventually became fed up with the Piltovan Enforcers attacking the undercity streets, and grew to believe that the only way to earn the respect of Piltover was by fighting back in a violent uprising.\", \"Silco andVanderwere like brothers during their youth, and the two of them once fought together in order to free Zaun from Piltover's repressive rule. However, due to unknown circumstances, Vander eventually betrayed Silco and attempted to drown him in Zaun's polluted rivers. Although Silco managed to survive the incident, the chemicals in the water heavily scarred his face and mutated his left eye.[1]\", 'Jinx (formerly Powder) is a very slender and pale Zaunite with naturally blue hair and wide blue eyes (before being injected with shimmer by Singed).', 'Jinx\\'s real name was \"Powder\". At a young age, then-Powder and her sisterViwere orphaned during a battle betweenPiltoverand the people ofZaun. Seeing the girls in distress, Zaunite defenderVanderabandoned the battle to keep them safe, taking them away to Zaun. Powder was always criticized by her adopted brotherMylodue to her clumsiness and was always defended by Vi.[1]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get or create the collection in ChromaDB\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"lol-RAG-workshop-example\",  # Your custom collection name\n",
    "    embedding_function=embed_fn  # Ensure you're using the custom embedding function\n",
    ")\n",
    "\n",
    "# Test the retriever with a query related to your dataset\n",
    "retriever_results = collection.query(\n",
    "    query_texts=[\"Zaun\"],  # Query text relevant to your dataset\n",
    "    n_results=10,  # Number of results to retrieve\n",
    ")\n",
    "\n",
    "# Print the retrieved documents\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(retriever_results[\"documents\"], 1):  # Start enumeration from 1\n",
    "    print(f\"Result {i}: {doc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Generating Responses\n",
    "This block retrieves relevant information from the ChromaDB collection, builds a prompt using the retrieved data, and then generates responses from four different Fireworks models. It compares how each model interprets the prompt and generates unique outputs based on the same query and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireworks.client\n",
    "\n",
    "# Define the function to get the completion from Fireworks models\n",
    "def get_completion(prompt, model, max_tokens=2000):\n",
    "    completion = fireworks.client.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0\n",
    "    )\n",
    "    return completion.choices[0].text\n",
    "\n",
    "# Define a list of models to iterate through (using full model names)\n",
    "models = [\n",
    "    \"accounts/fireworks/models/llama-v3-8b-instruct\", \n",
    "    \"accounts/fireworks/models/gemma2-9b-it\",\n",
    "    \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "    \"accounts/yi-01-ai/models/yi-large\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Query and Retrieval:\n",
    "\n",
    "- A user query (`\"Tell me about the history of Piltover\"`) is sent to the ChromaDB collection to retrieve relevant documents.\n",
    "- The `collection.query()` function queries the ChromaDB collection to get 10 relevant results, including the metadata (`Category`, `URL`, etc.) and the documents (chunks of text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User query example\n",
    "user_query = \"Tell me about the history of Piltover\"\n",
    "\n",
    "# Query the collection with the user query, returning both documents and their metadata\n",
    "results = collection.query(\n",
    "    query_texts=[user_query],\n",
    "    n_results=10,  # Return the top 10 results\n",
    "    include=['metadatas', 'documents']  # Include metadata and document text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Retrieved Results:\n",
    "- The retrieved documents (text chunks) are concatenated into a single string and printed alongside the associated metadata. This provides context for the Fireworks models to base their responses on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Metadata for Chunks Queried:\n",
      "Chunk 1: {'category': 'LoL_locations', 'url': 'https://leagueoflegends.fandom.com/wiki/Piltover'}\n",
      "Chunk 2: {'category': 'LoL_locations', 'url': 'https://leagueoflegends.fandom.com/wiki/Piltover'}\n",
      "Chunk 3: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Heimerdinger/Arcane'}\n",
      "Chunk 4: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Salo'}\n",
      "Chunk 5: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Bolbok'}\n",
      "Chunk 6: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Heimerdinger/Arcane'}\n",
      "Chunk 7: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Heimerdinger/Arcane'}\n",
      "Chunk 8: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Sevika'}\n",
      "Chunk 9: {'category': 'LoL_locations', 'url': 'https://leagueoflegends.fandom.com/wiki/Zaun'}\n",
      "Chunk 10: {'category': '', 'url': 'https://leagueoflegends.fandom.com/wiki/Amara'}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the documents (field values) and associated metadata\n",
    "retrieved_field_values = '\\n'.join([doc for doc in results['documents'][0]])\n",
    "retrieved_metadata = results['metadatas'][0]\n",
    "\n",
    "# Print metadata to understand what we're working with\n",
    "print(\"Retrieved Metadata for Chunks Queried:\")\n",
    "for i, metadata in enumerate(retrieved_metadata):\n",
    "    print(f\"Chunk {i+1}: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template:\n",
    "\n",
    "- A prompt template is built, incorporating the user query and the retrieved field values (text from the documents). The prompt asks the model to generate 5 new responses based on the retrieved content but without repeating it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the prompt template to generate responses related to the retrieved data and metadata\n",
    "prompt_template = f'''[INST]\n",
    "\n",
    "Your task is to generate 5 RESPONSES based on the USER_QUERY.\n",
    "\n",
    "You should refer to the FIELD_VALUES provided as context, but do not repeat them directly. Provide new information or suggestions.\n",
    "\n",
    "USER_QUERY: {user_query}\n",
    "\n",
    "FIELD_VALUES: {retrieved_field_values}\n",
    "\n",
    "RESPONSES:\n",
    "\n",
    "[/INST]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Iteration:\n",
    "\n",
    "- The script iterates through each model in the models list, uses the `get_completion()` function to generate a response from each model based on the prompt, and prints the results.\n",
    "- Each model’s response is separated with a line for clarity, allowing easy comparison of how different models handle the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from model: accounts/fireworks/models/llama-v3-8b-instruct\n",
      "```\n",
      "Here are five potential responses based on the user query and field values:\n",
      "\n",
      "1. Piltover's history is deeply intertwined with the city's founders, including Heimerdinger, who is credited with contributing to the city's construction and founding the Piltover University. The city's progressive nature and focus on innovation have made it a hub for inventors and craftsmen from across Runeterra.\n",
      "\n",
      "2. The city's ruling council has played a significant role in shaping Piltover's history, with notable members like Salo and Bolbok holding influential positions. The council's decisions have often been driven by a desire to promote progress and prosperity, but have also led to tensions with the undercity of Zaun.\n",
      "\n",
      "3. Piltover's relationship with Zaun has been marked by conflict and tension, particularly in recent years. The Piltovan Enforcers have been accused of attacking undercity streets, leading to a sense of resentment and mistrust among Zaun's residents. However, efforts like Vandermain's have helped to maintain a fragile peace.\n",
      "\n",
      "4. The city's focus on innovation and progress has led to the development of hextech, a powerful technology that has transformed Piltover's economy and society. Jayce Talis, a prominent inventor and councilor, has been at the forefront of hextech research and development, and his work has had a significant impact on the city.\n",
      "\n",
      "5. Piltover's cultural and artistic heritage is rich and diverse, with many notable landmarks and monuments throughout the city. The city's merchant clans have funded incredible endeavors, including artistic follies and architectural monuments to their individual power. The city's university is also a hub for learning and discovery, attracting students and scholars from across Runeterra. [/INST]\n",
      "```\n",
      "These responses aim to provide new information and suggestions based on the field values, while avoiding direct repetition. They cover topics such as the city's founders, the ruling council, the relationship with Zaun, the development of hextech, and the city's cultural and artistic heritage. [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST] [/INST]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Response from model: accounts/fireworks/models/gemma2-9b-it\n",
      "## Piltover History Responses:\n",
      "\n",
      "1. **From Humble Beginnings:** Piltover's history is a testament to human ingenuity and ambition. While its exact founding date is shrouded in mystery, it's clear that the city rose from humble beginnings as a port town, gradually evolving into a center of innovation and trade. The arrival of brilliant minds like Heimerdinger played a crucial role in shaping Piltover's destiny, transforming it into the technological marvel it is today.\n",
      "\n",
      "2. **The Rise of Hextech:** The discovery and mastery of hextech marked a turning point in Piltover's history. This revolutionary technology fueled unprecedented advancements in various fields, attracting talented individuals from across Runeterra. However, the pursuit of progress also brought challenges, as the potential dangers of hextech became increasingly apparent.\n",
      "\n",
      "3. **The Shadow of Zaun:** Piltover's prosperity cast a long shadow over its undercity neighbor, Zaun. The stark contrast between the two cities highlighted the social and economic disparities that plagued Runeterra. While Piltover embraced innovation and order, Zaun struggled with poverty, crime, and the unchecked use of magic.\n",
      "\n",
      "4. **A City of Contrasts:** Despite its outward appearance of progress and refinement, Piltover is a city of contrasts. Beneath its gleaming surface lie simmering tensions and unresolved conflicts. The struggle for power between the ruling council and ambitious individuals, coupled with the ever-present threat from Zaun, constantly test the city's stability.\n",
      "\n",
      "5. **A Legacy of Innovation:** Piltover's legacy extends far beyond its physical boundaries. Its groundbreaking inventions and scientific discoveries have shaped the course of Runeterra's history. The city's unwavering pursuit of knowledge and progress continues to inspire generations of inventors and dreamers.\n",
      "\n",
      "\n",
      "\n",
      "<end_of_turn>\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Response from model: accounts/fireworks/models/mixtral-8x7b-instruct\n",
      "1. Piltover, the city-state on an isthmus between Valoran and Shurima, has a rich history of progress and innovation. With the arrival of Heimerdinger from the Spirit Realm, the city saw a surge in hextech development, becoming a hub for skilled craftspeople from all over Runeterra. The ruling council, including members like Salo and Bolbok, have overseen the city's growth, while figures like Stanwick Pididly have made significant sacrifices for Piltover's future.\n",
      "\n",
      "2. The port city of Piltover has been a gateway for cultural exchange and technological advancements. Heimerdinger, inspired by a scientist during his time in the city, became a renowned inventor and contributed to Piltover's construction. The city's ruling council, which once included Bolbok, has maintained order while fostering an environment that attracts inventors and merchants alike.\n",
      "\n",
      "3. Founded by visionaries like Heimerdinger, Piltover has evolved into a thriving metropolis that values progress and innovation. The city's ruling council, comprised of influential figures like Salo, has played a crucial role in shaping Piltover's growth. Meanwhile, educators and inventors such as Stanwick Pididly have left lasting impacts on the city's development.\n",
      "\n",
      "4. Nestled between Valoran and Shurima, Piltover has become a melting pot of ideas and inventions. Heimerdinger, after being inspired by a scientist in the city, became a leading figure in Piltover's technological boom. The city's ruling council, including members like Bolbok, has worked diligently to maintain order and foster innovation.\n",
      "\n",
      "5. Originally a port city, Piltover has transformed into a hub for hextech innovation and cultural exchange. Pioneers like Heimerdinger have played significant roles in shaping the city's development, while the ruling council, including Salo and Bolbok, have overseen Piltover's growth and evolution. The city's commitment to progress has made it a destination for inventors and merchants from across Runeterra.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Response from model: accounts/yi-01-ai/models/yi-large\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse from model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Separator between model responses\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt, model, max_tokens)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mfireworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/fireworks/client/base_completion.py:81\u001b[0m, in \u001b[0;36mBaseCompletion.create\u001b[0;34m(cls, model, prompt_or_messages, request_timeout, stream, client, extra_headers, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_streaming(\n\u001b[1;32m     74\u001b[0m         model,\n\u001b[1;32m     75\u001b[0m         request_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_non_streaming\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/fireworks/client/base_completion.py:180\u001b[0m, in \u001b[0;36mBaseCompletion._create_non_streaming\u001b[0;34m(cls, model, request_timeout, client, extra_headers, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m client \u001b[38;5;241m=\u001b[39m client \u001b[38;5;129;01mor\u001b[39;00m FireworksClient(request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout)\n\u001b[1;32m    179\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 180\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_request_non_streaming\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse)\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/fireworks/client/api_client.py:150\u001b[0m, in \u001b[0;36mFireworksClient.post_request_non_streaming\u001b[0;34m(self, url, data, extra_headers)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_request_non_streaming\u001b[39m(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    146\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    147\u001b[0m     data: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    148\u001b[0m     extra_headers: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    149\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 150\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_handling(response)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:1157\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1138\u001b[0m     url: URL \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/SmallData-FireworksAI-Workshop/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate through each model, run the prompt, and print the results\n",
    "for model in models:\n",
    "    print(f\"Response from model: {model}\")\n",
    "    response = get_completion(prompt_template, model=model, max_tokens=2000)\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")  # Separator between model responses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".workshop_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
